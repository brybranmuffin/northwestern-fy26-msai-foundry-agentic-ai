{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Single Agent with Tool Calling\n",
    "\n",
    "Build an AI agent using **Microsoft Agent Framework** with tools from **3 different sources**:\n",
    "- Local Python functions\n",
    "- Logic Apps (from Lab 2)\n",
    "- Azure Functions (from Lab 1)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will:\n",
    "1. Create **local Python functions** as agent tools\n",
    "2. Add **Logic App** tools for email notifications\n",
    "3. Add **Azure Function** tools for heavy computation\n",
    "4. Understand the **data vs reasoning** pattern\n",
    "5. Build a complete **Graduate Research Assistant**\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "| Requirement | Setup |\n",
    "|------------|-------|\n",
    "| Python environment | Run `make start_env` from project root |\n",
    "| Azure CLI logged in | Run `az login` in terminal |\n",
    "| Azure AI Foundry Project | [Create at ai.azure.com](https://ai.azure.com) |\n",
    "| Model deployment | Deploy GPT-4o in your AI Foundry project |\n",
    "| Lab 1 (optional) | Azure Function for data analysis |\n",
    "| Lab 2 (optional) | Logic App for email notifications |\n",
    "\n",
    "## Environment Variables\n",
    "\n",
    "Create a `.env` file in the project root:\n",
    "\n",
    "```bash\n",
    "# Required\n",
    "AZURE_AI_PROJECT_ENDPOINT=https://your-project.services.ai.azure.com\n",
    "AZURE_AI_MODEL_DEPLOYMENT_NAME=gpt-4o\n",
    "\n",
    "# Optional (from Lab 1 & 2)\n",
    "AZURE_FUNCTION_URL=https://your-function.azurewebsites.net/api/analyze_data\n",
    "AZURE_FUNCTION_KEY=your-function-key\n",
    "LOGIC_APP_URL=https://prod-xx.eastus.logic.azure.com:443/workflows/...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ              Microsoft Agent Framework                          ‚îÇ\n",
    "‚îÇ                                                                 ‚îÇ\n",
    "‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n",
    "‚îÇ   ‚îÇ              AzureAIAgentsProvider                      ‚îÇ   ‚îÇ\n",
    "‚îÇ   ‚îÇ                                                         ‚îÇ   ‚îÇ\n",
    "‚îÇ   ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ   ‚îÇ\n",
    "‚îÇ   ‚îÇ   ‚îÇ  Agent  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ       4 Tools         ‚îÇ       ‚îÇ   ‚îÇ\n",
    "‚îÇ   ‚îÇ   ‚îÇ  (LLM)  ‚îÇ           ‚îÇ                       ‚îÇ       ‚îÇ   ‚îÇ\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ   ‚îÇ\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "             ‚îÇ                            ‚îÇ\n",
    "             ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "             ‚îÇ         ‚îÇ                  ‚îÇ                  ‚îÇ\n",
    "             ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "             ‚îÇ    ‚îÇ  Local  ‚îÇ      ‚îÇ  Logic App  ‚îÇ    ‚îÇ   Azure     ‚îÇ\n",
    "             ‚îÇ    ‚îÇFunctions‚îÇ      ‚îÇ   (Lab 2)   ‚îÇ    ‚îÇ  Function   ‚îÇ\n",
    "             ‚îÇ    ‚îÇ         ‚îÇ      ‚îÇ             ‚îÇ    ‚îÇ   (Lab 1)   ‚îÇ\n",
    "             ‚îÇ    ‚îÇ grades  ‚îÇ      ‚îÇ send_email  ‚îÇ    ‚îÇanalyze_data ‚îÇ\n",
    "             ‚îÇ    ‚îÇdeadlines‚îÇ      ‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ\n",
    "             ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "             ‚îÇ         ‚îÇ                  ‚îÇ                  ‚îÇ\n",
    "       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ                  ‚îÇ                  ‚îÇ\n",
    "       ‚îÇ  Reasons  ‚îÇ   ‚îÇ                  ‚îÇ                  ‚îÇ\n",
    "       ‚îÇ  about    ‚îÇ   ‚ñº                  ‚ñº                  ‚ñº\n",
    "       ‚îÇ  results  ‚îÇ  üìä DB           üìß Email          üî¢ Compute\n",
    "       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "**Key Concept**: The agent orchestrates tools from different sources:\n",
    "- **Local functions** ‚Äî Fast, in-process (database queries)\n",
    "- **Logic Apps** ‚Äî Workflow automation (emails, Slack, Teams)\n",
    "- **Azure Functions** ‚Äî Serverless compute (heavy processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Azure CLI found: /opt/homebrew/bin/az\n",
      "‚úÖ Loaded .env from /Users/pablo/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.env\n",
      "‚úÖ Environment configured\n",
      "   Project: https://aihubnw3478841489.services.ai.azure.com/ap...\n",
      "   Model: gpt-4o\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "from typing import Annotated\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import Field\n",
    "\n",
    "# Ensure Azure CLI is in PATH (Homebrew installs to /opt/homebrew/bin on Apple Silicon)\n",
    "# This is needed because the notebook kernel may not inherit the terminal's PATH\n",
    "homebrew_paths = [\"/opt/homebrew/bin\", \"/usr/local/bin\"]\n",
    "current_path = os.environ.get(\"PATH\", \"\")\n",
    "for p in homebrew_paths:\n",
    "    if p not in current_path:\n",
    "        os.environ[\"PATH\"] = p + \":\" + current_path\n",
    "        current_path = os.environ[\"PATH\"]\n",
    "\n",
    "# Verify az is accessible\n",
    "import shutil\n",
    "az_path = shutil.which(\"az\")\n",
    "if az_path:\n",
    "    print(f\"‚úÖ Azure CLI found: {az_path}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Azure CLI not found. Run: brew install azure-cli && az login\")\n",
    "\n",
    "# Load environment variables from project root\n",
    "# (notebook runs from notebooks/ folder, .env is in parent)\n",
    "env_path = Path(\"../.env\")\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(f\"‚úÖ Loaded .env from {env_path.resolve()}\")\n",
    "else:\n",
    "    load_dotenv()  # Try current directory\n",
    "    print(\"‚ö†Ô∏è  No .env found in parent directory, tried current directory\")\n",
    "\n",
    "# Verify required env vars\n",
    "required_vars = [\"AZURE_AI_PROJECT_ENDPOINT\", \"AZURE_AI_MODEL_DEPLOYMENT_NAME\"]\n",
    "missing = [v for v in required_vars if not os.getenv(v)]\n",
    "if missing:\n",
    "    print(f\"‚ùå Missing environment variables: {missing}\")\n",
    "    print(\"   Please create a .env file in the project root with:\")\n",
    "    print(\"   AZURE_AI_PROJECT_ENDPOINT=https://your-project.services.ai.azure.com\")\n",
    "    print(\"   AZURE_AI_MODEL_DEPLOYMENT_NAME=gpt-4o\")\n",
    "else:\n",
    "    print(\"‚úÖ Environment configured\")\n",
    "    print(f\"   Project: {os.getenv('AZURE_AI_PROJECT_ENDPOINT')[:50]}...\")\n",
    "    print(f\"   Model: {os.getenv('AZURE_AI_MODEL_DEPLOYMENT_NAME')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 2: Simulated Databases + Local Function Tools\n",
    "\n",
    "In a real application, the agent would query actual databases. Here we simulate:\n",
    "- **GRADES_DB** ‚Äî Student grades by course (assignment name, score, max, weight)\n",
    "- **DEADLINES_DB** ‚Äî Upcoming assignments (name, due date, priority)\n",
    "\n",
    "The agent uses **two tools** that query these databases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Simulated Databases Loaded:\n",
      "   GRADES_DB: 3 courses\n",
      "   DEADLINES_DB: 3 courses\n",
      "     ‚Ä¢ CS 101: 7 grades, 3 deadlines\n",
      "     ‚Ä¢ STAT 302: 6 grades, 3 deadlines\n",
      "     ‚Ä¢ ML 450: 4 grades, 3 deadlines\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SIMULATED DATABASES\n",
    "# In production, these would be real database queries\n",
    "# ============================================================\n",
    "\n",
    "# Grade database: course -> list of (assignment_name, score, max_score, weight)\n",
    "GRADES_DB = {\n",
    "    \"CS 101\": [\n",
    "        (\"Problem Set 1\", 92, 100, 0.10),\n",
    "        (\"Problem Set 2\", 85, 100, 0.10),\n",
    "        (\"Problem Set 3\", 78, 100, 0.10),\n",
    "        (\"Midterm Exam\", 88, 100, 0.25),\n",
    "        (\"Problem Set 4\", 95, 100, 0.10),\n",
    "        (\"Quiz 1\", 90, 100, 0.05),\n",
    "        (\"Quiz 2\", 82, 100, 0.05),\n",
    "        # Final not yet graded\n",
    "    ],\n",
    "    \"STAT 302\": [\n",
    "        (\"Homework 1\", 95, 100, 0.08),\n",
    "        (\"Homework 2\", 88, 100, 0.08),\n",
    "        (\"Homework 3\", 92, 100, 0.08),\n",
    "        (\"Lab Report 1\", 85, 100, 0.12),\n",
    "        (\"Midterm\", 79, 100, 0.25),\n",
    "        (\"Homework 4\", 90, 100, 0.08),\n",
    "    ],\n",
    "    \"ML 450\": [\n",
    "        (\"Assignment 1: Linear Regression\", 98, 100, 0.15),\n",
    "        (\"Assignment 2: Classification\", 94, 100, 0.15),\n",
    "        (\"Paper Review 1\", 88, 100, 0.10),\n",
    "        (\"Midterm Project\", 91, 100, 0.20),\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Deadline database: course -> list of (assignment_name, due_date, priority)\n",
    "DEADLINES_DB = {\n",
    "    \"CS 101\": [\n",
    "        (\"Problem Set 5\", \"2026-01-25\", \"High\"),\n",
    "        (\"Midterm Exam\", \"2026-02-01\", \"Critical\"),\n",
    "        (\"Final Project Proposal\", \"2026-02-15\", \"Medium\"),\n",
    "    ],\n",
    "    \"STAT 302\": [\n",
    "        (\"Regression Analysis Report\", \"2026-01-28\", \"High\"),\n",
    "        (\"Lab Report 2\", \"2026-02-05\", \"Medium\"),\n",
    "        (\"Final Project Proposal\", \"2026-02-10\", \"Medium\"),\n",
    "    ],\n",
    "    \"ML 450\": [\n",
    "        (\"Neural Network Lab\", \"2026-01-23\", \"Critical\"),\n",
    "        (\"Paper Review 2\", \"2026-01-30\", \"Medium\"),\n",
    "        (\"Final Project\", \"2026-02-20\", \"High\"),\n",
    "    ],\n",
    "}\n",
    "\n",
    "print(\"üìö Simulated Databases Loaded:\")\n",
    "print(f\"   GRADES_DB: {len(GRADES_DB)} courses\")\n",
    "print(f\"   DEADLINES_DB: {len(DEADLINES_DB)} courses\")\n",
    "for course in GRADES_DB:\n",
    "    print(f\"     ‚Ä¢ {course}: {len(GRADES_DB[course])} grades, {len(DEADLINES_DB.get(course, []))} deadlines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Two Local Tools\n",
    "\n",
    "These tools query the simulated databases and let the LLM reason about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Local tools defined:\n",
      "   ‚Ä¢ analyze_grades(course) ‚Äî Query grade database, return scores & statistics\n",
      "   ‚Ä¢ check_deadlines(course) ‚Äî Query deadline database, return due dates\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# TOOL 1: Analyze Grades\n",
    "# ============================================================\n",
    "\n",
    "def analyze_grades(\n",
    "    course: Annotated[str, Field(description=\"Course name to analyze (e.g., 'CS 101', 'STAT 302', 'ML 450')\")]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Query the grade database for a course and return detailed grade analysis.\n",
    "    Returns all assignment scores, calculated statistics, and current standing.\n",
    "    \"\"\"\n",
    "    # Find the course in database\n",
    "    course_key = None\n",
    "    for key in GRADES_DB:\n",
    "        if course.upper() in key.upper():\n",
    "            course_key = key\n",
    "            break\n",
    "    \n",
    "    if not course_key:\n",
    "        available = \", \".join(GRADES_DB.keys())\n",
    "        return f\"‚ùå Course '{course}' not found. Available courses: {available}\"\n",
    "    \n",
    "    grades = GRADES_DB[course_key]\n",
    "    \n",
    "    # Build detailed output\n",
    "    result = f\"üìä Grade Report for {course_key}\\n\"\n",
    "    result += \"=\" * 50 + \"\\n\\n\"\n",
    "    \n",
    "    # List all assignments\n",
    "    result += \"üìù Assignments Completed:\\n\"\n",
    "    scores = []\n",
    "    weighted_sum = 0\n",
    "    total_weight = 0\n",
    "    \n",
    "    for name, score, max_score, weight in grades:\n",
    "        pct = (score / max_score) * 100\n",
    "        scores.append(pct)\n",
    "        weighted_sum += pct * weight\n",
    "        total_weight += weight\n",
    "        \n",
    "        # Grade indicator\n",
    "        indicator = \"‚úÖ\" if pct >= 90 else \"üìó\" if pct >= 80 else \"üìô\" if pct >= 70 else \"üìï\"\n",
    "        result += f\"  {indicator} {name}: {score}/{max_score} ({pct:.1f}%) [weight: {weight*100:.0f}%]\\n\"\n",
    "    \n",
    "    # Calculate statistics\n",
    "    n = len(scores)\n",
    "    mean = sum(scores) / n\n",
    "    sorted_scores = sorted(scores)\n",
    "    median = sorted_scores[n // 2] if n % 2 else (sorted_scores[n//2 - 1] + sorted_scores[n//2]) / 2\n",
    "    variance = sum((s - mean) ** 2 for s in scores) / n\n",
    "    std_dev = variance ** 0.5\n",
    "    \n",
    "    # Current weighted grade\n",
    "    current_grade = weighted_sum / total_weight if total_weight > 0 else 0\n",
    "    letter = 'A' if current_grade >= 90 else 'B' if current_grade >= 80 else 'C' if current_grade >= 70 else 'D' if current_grade >= 60 else 'F'\n",
    "    \n",
    "    result += f\"\\nüìà Statistics:\\n\"\n",
    "    result += f\"  ‚Ä¢ Assignments graded: {n}\\n\"\n",
    "    result += f\"  ‚Ä¢ Average score: {mean:.1f}%\\n\"\n",
    "    result += f\"  ‚Ä¢ Median score: {median:.1f}%\\n\"\n",
    "    result += f\"  ‚Ä¢ Std deviation: {std_dev:.1f}%\\n\"\n",
    "    result += f\"  ‚Ä¢ Lowest: {min(scores):.1f}% | Highest: {max(scores):.1f}%\\n\"\n",
    "    \n",
    "    result += f\"\\nüéØ Current Standing:\\n\"\n",
    "    result += f\"  ‚Ä¢ Weighted grade: {current_grade:.1f}% ({letter})\\n\"\n",
    "    result += f\"  ‚Ä¢ Weight completed: {total_weight*100:.0f}% of course\\n\"\n",
    "    \n",
    "    # Trend analysis\n",
    "    if n >= 3:\n",
    "        recent_avg = sum(scores[-3:]) / 3\n",
    "        early_avg = sum(scores[:3]) / 3\n",
    "        trend = \"üìà Improving\" if recent_avg > early_avg + 2 else \"üìâ Declining\" if recent_avg < early_avg - 2 else \"‚û°Ô∏è Stable\"\n",
    "        result += f\"  ‚Ä¢ Trend: {trend}\\n\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TOOL 2: Check Deadlines\n",
    "# ============================================================\n",
    "\n",
    "def check_deadlines(\n",
    "    course: Annotated[str, Field(description=\"Course name to check deadlines for (e.g., 'CS 101', 'all')\")]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Query the deadline database and return upcoming assignments with due dates.\n",
    "    Use 'all' to see deadlines across all courses.\n",
    "    \"\"\"\n",
    "    today = datetime(2026, 1, 21)  # Current date for the simulation\n",
    "    \n",
    "    if course.lower() == \"all\":\n",
    "        result = \"üìÖ All Upcoming Deadlines\\n\"\n",
    "        result += \"=\" * 50 + \"\\n\\n\"\n",
    "        \n",
    "        # Collect all deadlines with course info\n",
    "        all_deadlines = []\n",
    "        for c, items in DEADLINES_DB.items():\n",
    "            for name, date_str, priority in items:\n",
    "                due_date = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "                days_until = (due_date - today).days\n",
    "                all_deadlines.append((c, name, date_str, priority, days_until))\n",
    "        \n",
    "        # Sort by days until due\n",
    "        all_deadlines.sort(key=lambda x: x[4])\n",
    "        \n",
    "        for c, name, date_str, priority, days_until in all_deadlines:\n",
    "            emoji = \"üî¥\" if priority == \"Critical\" else \"üü°\" if priority == \"High\" else \"üü¢\"\n",
    "            urgency = \"‚ö†Ô∏è OVERDUE!\" if days_until < 0 else f\"‚è∞ TODAY!\" if days_until == 0 else f\"üìÜ {days_until} days\"\n",
    "            result += f\"{emoji} [{c}] {name}\\n\"\n",
    "            result += f\"   Due: {date_str} ({urgency})\\n\"\n",
    "            result += f\"   Priority: {priority}\\n\\n\"\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    # Find specific course\n",
    "    course_key = None\n",
    "    for key in DEADLINES_DB:\n",
    "        if course.upper() in key.upper():\n",
    "            course_key = key\n",
    "            break\n",
    "    \n",
    "    if not course_key:\n",
    "        available = \", \".join(DEADLINES_DB.keys())\n",
    "        return f\"‚ùå Course '{course}' not found. Available courses: {available}\"\n",
    "    \n",
    "    deadlines = DEADLINES_DB[course_key]\n",
    "    \n",
    "    result = f\"üìÖ Deadlines for {course_key}\\n\"\n",
    "    result += \"=\" * 50 + \"\\n\\n\"\n",
    "    \n",
    "    for name, date_str, priority in deadlines:\n",
    "        due_date = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "        days_until = (due_date - today).days\n",
    "        \n",
    "        emoji = \"üî¥\" if priority == \"Critical\" else \"üü°\" if priority == \"High\" else \"üü¢\"\n",
    "        urgency = \"‚ö†Ô∏è OVERDUE!\" if days_until < 0 else f\"‚è∞ TODAY!\" if days_until == 0 else f\"üìÜ {days_until} days left\"\n",
    "        \n",
    "        result += f\"{emoji} {name}\\n\"\n",
    "        result += f\"   Due: {date_str} ({urgency})\\n\"\n",
    "        result += f\"   Priority: {priority}\\n\\n\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"‚úÖ Local tools defined:\")\n",
    "print(\"   ‚Ä¢ analyze_grades(course) ‚Äî Query grade database, return scores & statistics\")\n",
    "print(\"   ‚Ä¢ check_deadlines(course) ‚Äî Query deadline database, return due dates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Agent with AzureAIAgentsProvider\n",
    "\n",
    "The `AzureAIAgentsProvider` is the recommended way to create agents with Azure AI Foundry.\n",
    "\n",
    "**Key Methods:**\n",
    "- `create_agent()` ‚Äî Create a new agent on the service\n",
    "- `get_agent()` ‚Äî Retrieve an existing agent by ID\n",
    "- `as_agent()` ‚Äî Wrap an SDK agent without HTTP calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent created: GradResearchAssistantCoolbot\n",
      "   ID: asst_wz2uXpVk8pybxymVU9mu4fUp\n",
      "   Tools: analyze_grades, check_deadlines\n",
      "\n",
      "============================================================\n",
      "üì§ Student: What are my grades in CS 101?\n",
      "------------------------------------------------------------\n",
      "ü§ñ Assistant:\n",
      "Here is an analysis of your grades in CS 101:\n",
      "\n",
      "### Grades Breakdown:\n",
      "- **Problem Set 1:** 92/100 (92%) - Weight: 10%\n",
      "- **Problem Set 2:** 85/100 (85%) - Weight: 10%\n",
      "- **Problem Set 3:** 78/100 (78%) - Weight: 10%\n",
      "- **Midterm Exam:** 88/100 (88%) - Weight: 25%\n",
      "- **Problem Set 4:** 95/100 (95%) - Weight: 10%\n",
      "- **Quiz 1:** 90/100 (90%) - Weight: 5%\n",
      "- **Quiz 2:** 82/100 (82%) - Weight: 5%\n",
      "\n",
      "### Statistics:\n",
      "- **Average Score:** 87.1%\n",
      "- **Median Score:** 88%\n",
      "- **Lowest Score:** 78% | **Highest Score:** 95%\n",
      "- **Trend:** üìà Improving performance!\n",
      "\n",
      "### Weighted Grade:\n",
      "- **Current Weighted Grade:** 87.5% (B)\n",
      "- **Course Completed:** 75%\n",
      "\n",
      "You‚Äôre doing well overall, especially as your grades show improvement (e.g., Problem Set 4 is your highest score yet at 95%). However, try to focus on maintaining consistency‚ÄîProblem Set 3 and Quiz 2 dipped slightly below your average. Remember, you are on track to finish strong! Keep up the momentum!\n",
      "\n",
      "============================================================\n",
      "üì§ Student: Check all my upcoming deadlines\n",
      "------------------------------------------------------------\n",
      "ü§ñ Assistant:\n",
      "Here are your upcoming deadlines across all courses:\n",
      "\n",
      "### **Critical Deadlines**\n",
      "- **[ML 450] Neural Network Lab**: *Due in 2 days* (January 23, 2026)  \n",
      "- **[CS 101] Midterm Exam**: *Due in 11 days* (February 1, 2026)  \n",
      "\n",
      "### **High Priority Deadlines**\n",
      "- **[CS 101] Problem Set 5**: *Due in 4 days* (January 25, 2026)  \n",
      "- **[STAT 302] Regression Analysis Report**: *Due in 7 days* (January 28, 2026)  \n",
      "\n",
      "### **Medium Priority Deadlines**\n",
      "- **[ML 450] Paper Review 2**: *Due in 9 days* (January 30, 2026)  \n",
      "- **[STAT 302] Lab Report 2**: *Due in 15 days* (February 5, 2026)  \n",
      "- **[STAT 302] Final Project Proposal**: *Due in 20 days* (February 10, 2026)  \n",
      "- **[CS 101] Final Project Proposal**: *Due in 25 days* (February 15, 2026)  \n",
      "\n",
      "### **Long-Term High Priority Deadline**\n",
      "- **[ML 450] Final Project**: *Due in 30 days* (February 20, 2026)\n",
      "\n",
      "#### Suggestions:\n",
      "You should prioritize working on the **critical deadlines** first, especially the Neural Network Lab for ML 450 (due in only 2 days!). Let me know if you need assistance managing or strategizing for specific tasks!\n",
      "\n",
      "============================================================\n",
      "üì§ Student: How am I doing in STAT 302? Any deadlines I should worry about?\n",
      "------------------------------------------------------------\n",
      "ü§ñ Assistant:\n",
      "### üìä Grade Report for STAT 302:\n",
      "#### Completed Assignments:\n",
      "- **Homework 1**: 95/100 (95.0%) [Weight: 8%]\n",
      "- **Homework 2**: 88/100 (88.0%) [Weight: 8%]\n",
      "- **Homework 3**: 92/100 (92.0%) [Weight: 8%]\n",
      "- **Lab Report 1**: 85/100 (85.0%) [Weight: 12%]\n",
      "- **Midterm**: 79/100 (79.0%) [Weight: 25%]\n",
      "- **Homework 4**: 90/100 (90.0%) [Weight: 8%]\n",
      "\n",
      "#### üìà Statistics:\n",
      "- **Average Score**: 88.2%\n",
      "- **Median Score**: 89.0%\n",
      "- **Standard Deviation**: 5.1%\n",
      "- **Lowest Score**: 79.0% (Midterm)\n",
      "- **Highest Score**: 95.0% (Homework 1)\n",
      "\n",
      "#### üéØ Current Standing:\n",
      "- **Weighted Grade**: 85.7% (B)\n",
      "- **Weight Completed**: 69% of the course\n",
      "- **Performance Trend**: üìâ *Declining*\n",
      "\n",
      "‚ö†Ô∏è While your homework scores are strong, the midterm pulled your average down. To maintain or boost your grade, focus on upcoming assignments and aim for consistency, especially on major reports/projects.\n",
      "\n",
      "---\n",
      "\n",
      "### üìÖ Deadlines for STAT 302:\n",
      "#### üî¥ High Priority:\n",
      "- **Regression Analysis Report**\n",
      "  - **Due**: Jan 28, 2026 (7 days remaining)\n",
      "\n",
      "#### üü¢ Medium Priority:\n",
      "- **Lab Report 2**\n",
      "  - **Due**: Feb 5, 2026 (15 days remaining)\n",
      "- **Final Project Proposal**\n",
      "  - **Due**: Feb 10, 2026 (20 days remaining)\n",
      "\n",
      "---\n",
      "\n",
      "### Recommendations:\n",
      "1. **Regression Analysis Report**: As it's high priority and due in 7 days, allocate ample time to ensure quality.\n",
      "2. **Upcoming Lab and Final Proposal**: Begin planning earlier, so you're not overwhelmed close to their deadlines.\n",
      "3. **Grade Improvement**: Consider revisiting concepts or seeking help for areas that impacted your midterm score.\n",
      "\n",
      "You‚Äôve been handling assignments well, but consistent focus will help maintain your standing. Keep up the good work! üéì\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from agent_framework.azure import AzureAIAgentsProvider\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "\n",
    "async def run_basic_agent():\n",
    "    \"\"\"Create and run a Graduate Research Assistant with database tools.\"\"\"\n",
    "    \n",
    "    # DefaultAzureCredential tries multiple auth methods:\n",
    "    # 1. Environment variables (AZURE_CLIENT_ID, AZURE_TENANT_ID, AZURE_CLIENT_SECRET)\n",
    "    # 2. Managed Identity (if running in Azure)\n",
    "    # 3. Azure CLI (az login)\n",
    "    # 4. VS Code Azure extension\n",
    "    # 5. Interactive browser login\n",
    "    \n",
    "    async with (\n",
    "        DefaultAzureCredential() as credential,\n",
    "        AzureAIAgentsProvider(credential=credential) as provider,\n",
    "    ):\n",
    "        # Create agent with the two database tools\n",
    "        agent = await provider.create_agent(\n",
    "            name=\"GradResearchAssistantCoolbot\",\n",
    "            instructions=\"\"\"You are a Graduate Research Assistant AI helping students manage their academic work.\n",
    "\n",
    "You have access to two tools that query the student's academic databases:\n",
    "\n",
    "1. analyze_grades(course) ‚Äî Query the grade database for a specific course\n",
    "   Returns: All assignment scores, statistics, current weighted grade, trends\n",
    "   \n",
    "2. check_deadlines(course) ‚Äî Query the deadline database  \n",
    "   Use 'all' to see all courses, or specify a course name\n",
    "   Returns: Upcoming assignments with due dates and priority levels\n",
    "\n",
    "When a student asks about their academic performance:\n",
    "- Query the relevant databases using your tools\n",
    "- Analyze the data and provide helpful insights\n",
    "- If you notice concerning patterns (low grades, urgent deadlines), proactively mention them\n",
    "- Be encouraging but honest about areas needing improvement\"\"\",\n",
    "            tools=[analyze_grades, check_deadlines],\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Agent created: {agent.name}\")\n",
    "        print(f\"   ID: {agent.id}\")\n",
    "        print(f\"   Tools: analyze_grades, check_deadlines\\n\")\n",
    "        \n",
    "        # Test queries\n",
    "        queries = [\n",
    "            \"What are my grades in CS 101?\",\n",
    "            \"Check all my upcoming deadlines\",\n",
    "            \"How am I doing in STAT 302? Any deadlines I should worry about?\",\n",
    "        ]\n",
    "        \n",
    "        for query in queries:\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"üì§ Student: {query}\")\n",
    "            print(\"-\" * 60)\n",
    "            result = await agent.run(query)\n",
    "            print(f\"ü§ñ Assistant:\\n{result}\")\n",
    "            print()\n",
    "\n",
    "# Run the agent\n",
    "await run_basic_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Add Logic App Tool (Email Notifications)\n",
    "\n",
    "Now let's add a **Logic App** tool that the agent can use to send email notifications.\n",
    "This connects to the workflow you built in **Lab 2**.\n",
    "\n",
    "**Use Cases:**\n",
    "- Send deadline reminders to students\n",
    "- Email grade reports\n",
    "- Alert when grades drop below a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Logic App configured - send_email tool ready\n",
      "   URL: https://prod-04.northcentralus.logic.azure.com:443...\n"
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "\n",
    "# ============================================================\n",
    "# TOOL 3: Send Email via Logic App (from Lab 2)\n",
    "# ============================================================\n",
    "\n",
    "def create_email_tool(logic_app_url: str):\n",
    "    \"\"\"Create a tool that sends emails via Logic App workflow.\"\"\"\n",
    "    \n",
    "    async def send_email(\n",
    "        to: Annotated[str, Field(description=\"Recipient email address\")],\n",
    "        subject: Annotated[str, Field(description=\"Email subject line\")],\n",
    "        message: Annotated[str, Field(description=\"Email body content\")]\n",
    "    ) -> str:\n",
    "        \"\"\"Send an email notification using Logic App workflow.\"\"\"\n",
    "        try:\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                async with session.post(\n",
    "                    logic_app_url,\n",
    "                    headers={\"Content-Type\": \"application/json\"},\n",
    "                    json={\"to\": to, \"subject\": subject, \"message\": message},\n",
    "                    timeout=aiohttp.ClientTimeout(total=30)\n",
    "                ) as response:\n",
    "                    if response.status in [200, 202]:\n",
    "                        return f\"‚úÖ Email sent successfully!\\n   To: {to}\\n   Subject: {subject}\"\n",
    "                    else:\n",
    "                        return f\"‚ùå Email failed: HTTP {response.status}\"\n",
    "        except Exception as e:\n",
    "            return f\"‚ùå Email error: {str(e)}\"\n",
    "    \n",
    "    return send_email\n",
    "\n",
    "\n",
    "# Check if Logic App is configured (from Lab 2)\n",
    "logic_app_url = os.getenv(\"LOGIC_APP_URL\")\n",
    "\n",
    "if logic_app_url:\n",
    "    send_email = create_email_tool(logic_app_url)\n",
    "    print(\"‚úÖ Logic App configured - send_email tool ready\")\n",
    "    print(f\"   URL: {logic_app_url[:50]}...\")\n",
    "else:\n",
    "    # Mock function for demo when Logic App not configured\n",
    "    async def send_email(\n",
    "        to: Annotated[str, Field(description=\"Recipient email address\")],\n",
    "        subject: Annotated[str, Field(description=\"Email subject line\")],\n",
    "        message: Annotated[str, Field(description=\"Email body content\")]\n",
    "    ) -> str:\n",
    "        \"\"\"Send an email notification (mock - simulates Logic App).\"\"\"\n",
    "        return f\"\"\"üìß Email Sent (Mock - Logic App not configured)\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "To: {to}\n",
    "Subject: {subject}\n",
    "Message: {message}\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "Status: ‚úì Delivered (simulated)\n",
    "\n",
    "üí° To use real emails, set LOGIC_APP_URL from Lab 2\"\"\"\n",
    "    \n",
    "    print(\"‚ö†Ô∏è  LOGIC_APP_URL not set - using mock send_email\")\n",
    "    print(\"   Set LOGIC_APP_URL from Lab 2 to send real emails\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Add Azure Function Tool (Data Analysis)\n",
    "\n",
    "Finally, let's add an **Azure Function** tool for heavy computation.\n",
    "This connects to the function you built in **Lab 1**.\n",
    "\n",
    "**Use Cases:**\n",
    "- Statistical analysis on large datasets\n",
    "- Run computations that shouldn't run in-process\n",
    "- Offload CPU-intensive work to serverless compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  AZURE_FUNCTION_URL not set - using mock analyze_data\n",
      "   Set AZURE_FUNCTION_URL from Lab 1 for serverless compute\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# TOOL 4: Analyze Data via Azure Function (from Lab 1)\n",
    "# ============================================================\n",
    "\n",
    "def create_analyze_data_tool(function_url: str, function_key: str | None = None):\n",
    "    \"\"\"Create a tool that calls Azure Function for data analysis.\"\"\"\n",
    "    \n",
    "    async def analyze_data(\n",
    "        values: Annotated[str, Field(description=\"Comma-separated numbers to analyze (e.g., '10,20,30,40,50')\")]\n",
    "    ) -> str:\n",
    "        \"\"\"Analyze numerical data using Azure Function (heavy computation).\"\"\"\n",
    "        try:\n",
    "            # Parse the comma-separated values\n",
    "            numbers = [float(v.strip()) for v in values.split(',')]\n",
    "            \n",
    "            headers = {\"Content-Type\": \"application/json\"}\n",
    "            if function_key:\n",
    "                headers[\"x-functions-key\"] = function_key\n",
    "            \n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                async with session.post(\n",
    "                    function_url,\n",
    "                    headers=headers,\n",
    "                    json={\"values\": numbers},\n",
    "                    timeout=aiohttp.ClientTimeout(total=60)\n",
    "                ) as response:\n",
    "                    if response.status == 200:\n",
    "                        result = await response.json()\n",
    "                        return f\"\"\"üìä Azure Function Analysis Results:\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "Count: {result.get('count', 'N/A')}\n",
    "Sum: {result.get('sum', 'N/A')}\n",
    "Mean: {result.get('mean', 'N/A'):.2f}\n",
    "Min: {result.get('min', 'N/A')}\n",
    "Max: {result.get('max', 'N/A')}\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\"\"\"\n",
    "                    else:\n",
    "                        return f\"‚ùå Function error: HTTP {response.status}\"\n",
    "        except Exception as e:\n",
    "            return f\"‚ùå Analysis error: {str(e)}\"\n",
    "    \n",
    "    return analyze_data\n",
    "\n",
    "\n",
    "# Check if Azure Function is configured (from Lab 1)\n",
    "azure_function_url = os.getenv(\"AZURE_FUNCTION_URL\")\n",
    "azure_function_key = os.getenv(\"AZURE_FUNCTION_KEY\")\n",
    "\n",
    "if azure_function_url:\n",
    "    analyze_data = create_analyze_data_tool(azure_function_url, azure_function_key)\n",
    "    print(\"‚úÖ Azure Function configured - analyze_data tool ready\")\n",
    "    print(f\"   URL: {azure_function_url[:50]}...\")\n",
    "else:\n",
    "    # Mock function for demo when Azure Function not configured\n",
    "    async def analyze_data(\n",
    "        values: Annotated[str, Field(description=\"Comma-separated numbers to analyze (e.g., '10,20,30,40,50')\")]\n",
    "    ) -> str:\n",
    "        \"\"\"Analyze numerical data (mock - simulates Azure Function).\"\"\"\n",
    "        try:\n",
    "            numbers = [float(v.strip()) for v in values.split(',')]\n",
    "            n = len(numbers)\n",
    "            total = sum(numbers)\n",
    "            mean = total / n\n",
    "            \n",
    "            return f\"\"\"üìä Data Analysis Results (Mock - Azure Function not configured)\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "Count: {n}\n",
    "Sum: {total:.2f}\n",
    "Mean: {mean:.2f}\n",
    "Min: {min(numbers):.2f}\n",
    "Max: {max(numbers):.2f}\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "\n",
    "üí° To use Azure Function, set AZURE_FUNCTION_URL from Lab 1\"\"\"\n",
    "        except Exception as e:\n",
    "            return f\"‚ùå Error parsing values: {str(e)}. Use comma-separated numbers.\"\n",
    "    \n",
    "    print(\"‚ö†Ô∏è  AZURE_FUNCTION_URL not set - using mock analyze_data\")\n",
    "    print(\"   Set AZURE_FUNCTION_URL from Lab 1 for serverless compute\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Step 7: Complete Graduate Research Assistant\n",
    "\n",
    "Now let's create the full agent with all **4 tools** and test a complex multi-step query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Complete Research Assistant ready with 4 tools\n",
      "\n",
      "======================================================================\n",
      "üì§ Student Query:\n",
      "\n",
      "        I'm preparing for finals. Can you:\n",
      "        1. Check all my upcoming deadlines\n",
      "        2. Show me how I'm doing in ML 450\n",
      "        3. Run a statistical analysis on my ML 450 scores\n",
      "        4. Send me an email summary to student@northwestern.edu\n",
      "        \n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     49\u001b[39m         \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Run the complete assistant\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_complete_assistant()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mrun_complete_assistant\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28mprint\u001b[39m(complex_query)\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m agent.run(complex_query)\n\u001b[32m     48\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mü§ñ Research Assistant Response:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     49\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/agent_framework/_middleware.py:1253\u001b[39m, in \u001b[36muse_agent_middleware.<locals>.middleware_enabled_run\u001b[39m\u001b[34m(self, messages, thread, middleware, **kwargs)\u001b[39m\n\u001b[32m   1250\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;28;01melse\u001b[39;00m AgentResponse()\n\u001b[32m   1252\u001b[39m \u001b[38;5;66;03m# No middleware, execute directly\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1253\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m original_run(\u001b[38;5;28mself\u001b[39m, normalized_messages, thread=thread, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/agent_framework/observability.py:1342\u001b[39m, in \u001b[36m_trace_agent_run.<locals>.trace_run\u001b[39m\u001b[34m(self, messages, thread, **kwargs)\u001b[39m\n\u001b[32m   1338\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m OBSERVABILITY_SETTINGS\n\u001b[32m   1340\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m OBSERVABILITY_SETTINGS.ENABLED:\n\u001b[32m   1341\u001b[39m     \u001b[38;5;66;03m# If model diagnostics are not enabled, just return the completion\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1342\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m run_func(\u001b[38;5;28mself\u001b[39m, messages=messages, thread=thread, **kwargs)\n\u001b[32m   1344\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m merge_chat_options\n\u001b[32m   1346\u001b[39m default_options = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdefault_options\u001b[39m\u001b[33m\"\u001b[39m, {})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/agent_framework/_agents.py:854\u001b[39m, in \u001b[36mChatAgent.run\u001b[39m\u001b[34m(self, messages, thread, tools, options, **kwargs)\u001b[39m\n\u001b[32m    852\u001b[39m \u001b[38;5;66;03m# Filter chat_options from kwargs to prevent duplicate keyword argument\u001b[39;00m\n\u001b[32m    853\u001b[39m filtered_kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k != \u001b[33m\"\u001b[39m\u001b[33mchat_options\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m--> \u001b[39m\u001b[32m854\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chat_client.get_response(\n\u001b[32m    855\u001b[39m     messages=thread_messages,\n\u001b[32m    856\u001b[39m     options=co,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    857\u001b[39m     **filtered_kwargs,\n\u001b[32m    858\u001b[39m )\n\u001b[32m    860\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._update_thread_with_type_and_conversation_id(thread, response.conversation_id)\n\u001b[32m    862\u001b[39m \u001b[38;5;66;03m# Ensure that the author name is set for each message in the response.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/agent_framework/_tools.py:1927\u001b[39m, in \u001b[36m_handle_function_calls_response.<locals>.decorator.<locals>.function_invocation_wrapper\u001b[39m\u001b[34m(self, messages, options, **kwargs)\u001b[39m\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# Filter out internal framework kwargs before passing to clients.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;66;03m# Also exclude tools and tool_choice since they are now in options dict.\u001b[39;00m\n\u001b[32m   1926\u001b[39m filtered_kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mthread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m)}\n\u001b[32m-> \u001b[39m\u001b[32m1927\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, messages=prepped_messages, options=options, **filtered_kwargs)\n\u001b[32m   1928\u001b[39m \u001b[38;5;66;03m# if there are function calls, we will handle them first\u001b[39;00m\n\u001b[32m   1929\u001b[39m function_results = {\n\u001b[32m   1930\u001b[39m     it.call_id \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m response.messages[\u001b[32m0\u001b[39m].contents \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(it, FunctionResultContent)\n\u001b[32m   1931\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/agent_framework/observability.py:1073\u001b[39m, in \u001b[36m_trace_get_response.<locals>.decorator.<locals>.trace_get_response\u001b[39m\u001b[34m(self, messages, options, **kwargs)\u001b[39m\n\u001b[32m   1070\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m OBSERVABILITY_SETTINGS\n\u001b[32m   1071\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m OBSERVABILITY_SETTINGS.ENABLED:\n\u001b[32m   1072\u001b[39m     \u001b[38;5;66;03m# If model_id diagnostics are not enabled, just return the completion\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1073\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\n\u001b[32m   1074\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1075\u001b[39m         messages=messages,\n\u001b[32m   1076\u001b[39m         options=options,\n\u001b[32m   1077\u001b[39m         **kwargs,\n\u001b[32m   1078\u001b[39m     )\n\u001b[32m   1079\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtoken_usage_histogram\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.additional_properties:\n\u001b[32m   1080\u001b[39m     \u001b[38;5;28mself\u001b[39m.additional_properties[\u001b[33m\"\u001b[39m\u001b[33mtoken_usage_histogram\u001b[39m\u001b[33m\"\u001b[39m] = _get_token_usage_histogram()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/agent_framework/_middleware.py:1373\u001b[39m, in \u001b[36muse_chat_middleware.<locals>.middleware_enabled_get_response\u001b[39m\u001b[34m(self, messages, options, **kwargs)\u001b[39m\n\u001b[32m   1371\u001b[39m \u001b[38;5;66;03m# If no chat middleware, use original method\u001b[39;00m\n\u001b[32m   1372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chat_middleware_list:\n\u001b[32m-> \u001b[39m\u001b[32m1373\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m original_get_response(\n\u001b[32m   1374\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1375\u001b[39m         messages,\n\u001b[32m   1376\u001b[39m         options=options,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   1377\u001b[39m         **kwargs,\n\u001b[32m   1378\u001b[39m     )\n\u001b[32m   1380\u001b[39m \u001b[38;5;66;03m# Create pipeline and execute with middleware\u001b[39;00m\n\u001b[32m   1381\u001b[39m pipeline = ChatMiddlewarePipeline(chat_middleware_list)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/agent_framework/_clients.py:339\u001b[39m, in \u001b[36mBaseChatClient.get_response\u001b[39m\u001b[34m(self, messages, options, **kwargs)\u001b[39m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_response\u001b[39m(\n\u001b[32m    323\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    324\u001b[39m     messages: \u001b[38;5;28mstr\u001b[39m | ChatMessage | Sequence[\u001b[38;5;28mstr\u001b[39m | ChatMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    327\u001b[39m     **kwargs: Any,\n\u001b[32m    328\u001b[39m ) -> ChatResponse:\n\u001b[32m    329\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get a response from a chat client.\u001b[39;00m\n\u001b[32m    330\u001b[39m \n\u001b[32m    331\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    337\u001b[39m \u001b[33;03m        A chat response from the model.\u001b[39;00m\n\u001b[32m    338\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inner_get_response(\n\u001b[32m    340\u001b[39m         messages=prepare_messages(messages),\n\u001b[32m    341\u001b[39m         options=\u001b[38;5;28;01mawait\u001b[39;00m validate_chat_options(\u001b[38;5;28mdict\u001b[39m(options) \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[32m    342\u001b[39m         **kwargs,\n\u001b[32m    343\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/agent_framework_azure_ai/_chat_client.py:355\u001b[39m, in \u001b[36mAzureAIAgentClient._inner_get_response\u001b[39m\u001b[34m(self, messages, options, **kwargs)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_inner_get_response\u001b[39m(\n\u001b[32m    349\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    353\u001b[39m     **kwargs: Any,\n\u001b[32m    354\u001b[39m ) -> ChatResponse:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m ChatResponse.from_chat_response_generator(\n\u001b[32m    356\u001b[39m         updates=\u001b[38;5;28mself\u001b[39m._inner_get_streaming_response(messages=messages, options=options, **kwargs),\n\u001b[32m    357\u001b[39m         output_format_type=options.get(\u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    358\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/agent_framework/_types.py:2920\u001b[39m, in \u001b[36mChatResponse.from_chat_response_generator\u001b[39m\u001b[34m(cls, updates, output_format_type)\u001b[39m\n\u001b[32m   2900\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Joins multiple updates into a single ChatResponse.\u001b[39;00m\n\u001b[32m   2901\u001b[39m \n\u001b[32m   2902\u001b[39m \u001b[33;03mExample:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2917\u001b[39m \u001b[33;03m    output_format_type: Optional Pydantic model type to parse the response text into structured data.\u001b[39;00m\n\u001b[32m   2918\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2919\u001b[39m msg = \u001b[38;5;28mcls\u001b[39m(messages=[])\n\u001b[32m-> \u001b[39m\u001b[32m2920\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m update \u001b[38;5;129;01min\u001b[39;00m updates:\n\u001b[32m   2921\u001b[39m     _process_update(msg, update)\n\u001b[32m   2922\u001b[39m _finalize_response(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/agent_framework_azure_ai/_chat_client.py:373\u001b[39m, in \u001b[36mAzureAIAgentClient._inner_get_streaming_response\u001b[39m\u001b[34m(self, messages, options, **kwargs)\u001b[39m\n\u001b[32m    370\u001b[39m agent_id = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_agent_id_or_create(run_options)\n\u001b[32m    372\u001b[39m \u001b[38;5;66;03m# execute and process\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m update \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_stream(\n\u001b[32m    374\u001b[39m     *(\u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_agent_stream(agent_id, run_options, required_action_results))\n\u001b[32m    375\u001b[39m ):\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m update\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/agent_framework_azure_ai/_chat_client.py:634\u001b[39m, in \u001b[36mAzureAIAgentClient._process_stream\u001b[39m\u001b[34m(self, stream, thread_id)\u001b[39m\n\u001b[32m    632\u001b[39m response_stream = \u001b[38;5;28;01mawait\u001b[39;00m stream.\u001b[34m__aenter__\u001b[39m() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stream, AsyncAgentRunStream) \u001b[38;5;28;01melse\u001b[39;00m stream  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event_type, event_data, _ \u001b[38;5;129;01min\u001b[39;00m response_stream:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    635\u001b[39m         \u001b[38;5;28;01mmatch\u001b[39;00m event_data:\n\u001b[32m    636\u001b[39m             \u001b[38;5;28;01mcase\u001b[39;00m MessageDeltaChunk():\n\u001b[32m    637\u001b[39m                 \u001b[38;5;66;03m# only one event_type: AgentStreamEvent.THREAD_MESSAGE_DELTA\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/azure/ai/agents/models/_patch.py:2061\u001b[39m, in \u001b[36mBaseAsyncAgentEventHandler.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2059\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__anext__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> T:\n\u001b[32m   2060\u001b[39m     \u001b[38;5;66;03m# cspell:disable-next-line\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2061\u001b[39m     event_bytes = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__anext_impl__()\n\u001b[32m   2062\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_event(event_bytes.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/azure/ai/agents/models/_patch.py:2071\u001b[39m, in \u001b[36mBaseAsyncAgentEventHandler.__anext_impl__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2068\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThe response handler was not initialized.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2070\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.buffer:\n\u001b[32m-> \u001b[39m\u001b[32m2071\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.response_iterator:\n\u001b[32m   2072\u001b[39m         \u001b[38;5;28mself\u001b[39m.buffer += chunk\n\u001b[32m   2073\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.buffer:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/azure/core/rest/_http_response_impl_async.py:119\u001b[39m, in \u001b[36mAsyncHttpResponseImpl.iter_bytes\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28mself\u001b[39m._stream_download_check()\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stream_download_generator(response=\u001b[38;5;28mself\u001b[39m, pipeline=\u001b[38;5;28;01mNone\u001b[39;00m, decompress=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    120\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m part\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/azure/core/pipeline/transport/_aiohttp.py:448\u001b[39m, in \u001b[36mAioHttpStreamDownloadGenerator.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    446\u001b[39m internal_response = \u001b[38;5;28mself\u001b[39m.response.internal_response\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m448\u001b[39m     chunk = \u001b[38;5;28;01mawait\u001b[39;00m internal_response.content.read(\u001b[38;5;28mself\u001b[39m.block_size)\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunk:\n\u001b[32m    450\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m _ResponseStopIteration()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/aiohttp/streams.py:452\u001b[39m, in \u001b[36mStreamReader.read\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;66;03m# TODO: should be `if` instead of `while`\u001b[39;00m\n\u001b[32m    449\u001b[39m \u001b[38;5;66;03m# because waiter maybe triggered on chunk end,\u001b[39;00m\n\u001b[32m    450\u001b[39m \u001b[38;5;66;03m# without feeding any data\u001b[39;00m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._eof:\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._read_nowait(n)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/aiohttp/streams.py:371\u001b[39m, in \u001b[36mStreamReader._wait\u001b[39m\u001b[34m(self, func_name)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._timer:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m waiter\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    373\u001b[39m     \u001b[38;5;28mself\u001b[39m._waiter = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.14-macos-aarch64-none/lib/python3.11/asyncio/futures.py:287\u001b[39m, in \u001b[36mFuture.__await__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    286\u001b[39m     \u001b[38;5;28mself\u001b[39m._asyncio_future_blocking = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    289\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mawait wasn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt used with future\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "async def run_complete_assistant():\n",
    "    \"\"\"Create the complete Graduate Research Assistant with all 4 tools.\"\"\"\n",
    "    \n",
    "    async with (\n",
    "        DefaultAzureCredential() as credential,\n",
    "        AzureAIAgentsProvider(credential=credential) as provider,\n",
    "    ):\n",
    "        agent = await provider.create_agent(\n",
    "            name=\"GradResearchAssistant\",\n",
    "            instructions=\"\"\"You are a Graduate Research Assistant AI helping students succeed.\n",
    "            \n",
    "Your capabilities (4 tools):\n",
    "üìä analyze_grades(course) ‚Äî Query grade database for a specific course\n",
    "üìÖ check_deadlines(course) ‚Äî Query deadline database (use 'all' for all courses)\n",
    "üìß send_email(to, subject, message) ‚Äî Send email notifications via Logic App\n",
    "üî¢ analyze_data(values) ‚Äî Statistical analysis via Azure Function\n",
    "\n",
    "When helping students:\n",
    "1. Query databases to understand their situation\n",
    "2. If they need analysis, use the Azure Function for computation\n",
    "3. If they want reminders or notifications, use the email tool\n",
    "4. Be proactive about identifying concerns and suggesting solutions\"\"\",\n",
    "            tools=[\n",
    "                analyze_grades,      # Local - query grade DB\n",
    "                check_deadlines,     # Local - query deadline DB\n",
    "                send_email,          # Logic App - notifications\n",
    "                analyze_data,        # Azure Function - computation\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Complete Research Assistant ready with 4 tools\\n\")\n",
    "        \n",
    "        # Complex multi-step query that uses multiple tools\n",
    "        complex_query = \"\"\"\n",
    "        I'm preparing for finals. Can you:\n",
    "        1. Check all my upcoming deadlines\n",
    "        2. Show me how I'm doing in ML 450\n",
    "        3. Run a statistical analysis on my ML 450 scores\n",
    "        4. Send me an email summary to student@northwestern.edu\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\"üì§ Student Query:\")\n",
    "        print(complex_query)\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        result = await agent.run(complex_query)\n",
    "        print(\"\\nü§ñ Research Assistant Response:\")\n",
    "        print(result)\n",
    "\n",
    "# Run the complete assistant\n",
    "await run_complete_assistant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Interactive Chat Session\n",
    "\n",
    "Chat with your agent using all 4 tools!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéì Graduate Research Assistant Ready!\n",
      "============================================================\n",
      "Available tools:\n",
      "  üìä Grades     ‚Äî 'How am I doing in CS 101?'\n",
      "  üìÖ Deadlines  ‚Äî 'Check my deadlines'\n",
      "  üìß Email      ‚Äî 'Email me a summary'\n",
      "  üî¢ Analysis   ‚Äî 'Analyze these scores: 85,90,78,92'\n",
      "\n",
      "Courses in database: CS 101, STAT 302, ML 450\n",
      "Type 'quit' to exit\n",
      "============================================================\n",
      "\n",
      "‚è≥ Thinking...\n",
      "\n",
      "ü§ñ Assistant: Could you please specify the course name for which you'd like to check the deadlines, or would you like to see deadlines across all courses?\n",
      "\n",
      "‚è≥ Thinking...\n",
      "\n",
      "ü§ñ Assistant: Here are your upcoming deadlines across all courses:\n",
      "\n",
      "üî¥ **Critical Priority**\n",
      "- [ML 450] Neural Network Lab - Due: **January 23, 2026** (2 days left)\n",
      "- [CS 101] Midterm Exam - Due: **February 01, 2026** (11 days left)\n",
      "\n",
      "üü° **High Priority**\n",
      "- [CS 101] Problem Set 5 - Due: **January 25, 2026** (4 days left)\n",
      "- [STAT 302] Regression Analysis Report - Due: **January 28, 2026** (7 days left)\n",
      "- [ML 450] Final Project - Due: **February 20, 2026** (30 days left)\n",
      "\n",
      "üü¢ **Medium Priority**\n",
      "- [ML 450] Paper Review 2 - Due: **January 30, 2026** (9 days left)\n",
      "- [STAT 302] Lab Report 2 - Due: **February 05, 2026** (15 days left)\n",
      "- [STAT 302] Final Project Proposal - Due: **February 10, 2026** (20 days left)\n",
      "- [CS 101] Final Project Proposal - Due: **February 15, 2026** (25 days left)\n",
      "\n",
      "Let me know if you'd like help prioritizing or email reminders for any of these tasks!\n",
      "\n",
      "‚è≥ Thinking...\n",
      "\n",
      "ü§ñ Assistant: The email with your upcoming deadlines has been successfully sent to **pablosal@microsoft.com**. Let me know if there‚Äôs anything else I can assist you with!\n",
      "\n",
      "üëã Goodbye! Good luck with your studies!\n"
     ]
    }
   ],
   "source": [
    "async def interactive_research_session():\n",
    "    \"\"\"Run an interactive session with all 4 tools.\"\"\"\n",
    "    \n",
    "    async with (\n",
    "        DefaultAzureCredential() as credential,\n",
    "        AzureAIAgentsProvider(credential=credential) as provider,\n",
    "    ):\n",
    "        agent = await provider.create_agent(\n",
    "            name=\"GradAssistant\",\n",
    "            instructions=\"\"\"You are a helpful Graduate Research Assistant with 4 tools:\n",
    "- analyze_grades: Query grade database\n",
    "- check_deadlines: Query deadline database  \n",
    "- send_email: Send email notifications\n",
    "\n",
    "Help students with their academic needs.\"\"\",\n",
    "            tools=[analyze_grades, check_deadlines, send_email],\n",
    "        )\n",
    "        \n",
    "        # Get a new thread for conversation history\n",
    "        thread = agent.get_new_thread()\n",
    "        \n",
    "        print(\"üéì Graduate Research Assistant Ready!\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"Available tools:\")\n",
    "        print(\"  üìä Grades     ‚Äî 'How am I doing in CS 101?'\")\n",
    "        print(\"  üìÖ Deadlines  ‚Äî 'Check my deadlines'\")\n",
    "        print(\"  üìß Email      ‚Äî 'Email me a summary'\")\n",
    "        print(\"  üî¢ Analysis   ‚Äî 'Analyze these scores: 85,90,78,92'\")\n",
    "        print()\n",
    "        print(\"Courses in database: CS 101, STAT 302, ML 450\")\n",
    "        print(\"Type 'quit' to exit\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                user_input = input(\"\\nüìù You: \").strip()\n",
    "            except EOFError:\n",
    "                break\n",
    "                \n",
    "            if not user_input:\n",
    "                continue\n",
    "            if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "                print(\"\\nüëã Goodbye! Good luck with your studies!\")\n",
    "                break\n",
    "            \n",
    "            print(\"\\n‚è≥ Thinking...\")\n",
    "            # Pass the thread to agent.run() to maintain conversation history\n",
    "            response = await agent.run(user_input, thread=thread)\n",
    "            print(f\"\\nü§ñ Assistant: {response}\")\n",
    "\n",
    "# Run interactive session\n",
    "await interactive_research_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Gradio Chat Interface üé®\n",
    "\n",
    "Launch your UI (frontend).."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x115b05110>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x115b07d10>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Launching Gradio interface...\n",
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"700\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent initialized!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/xk/hfc2dqx96qz5k3x7sg0sm2wh0000gn/T/ipykernel_12611/4158950673.py\", line 50, in chat\n",
      "    response = await self.agent.run(message, thread=self.thread)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pablo/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/agent_framework/_middleware.py\", line 1253, in middleware_enabled_run\n",
      "    return await original_run(self, normalized_messages, thread=thread, **kwargs)  # type: ignore[return-value]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pablo/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/agent_framework/observability.py\", line 1342, in trace_run\n",
      "    return await run_func(self, messages=messages, thread=thread, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pablo/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/agent_framework/_agents.py\", line 854, in run\n",
      "    response = await self.chat_client.get_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pablo/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/agent_framework/_tools.py\", line 1927, in function_invocation_wrapper\n",
      "    response = await func(self, messages=prepped_messages, options=options, **filtered_kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pablo/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/agent_framework/observability.py\", line 1073, in trace_get_response\n",
      "    return await func(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/pablo/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/agent_framework/_middleware.py\", line 1373, in middleware_enabled_get_response\n",
      "    return await original_get_response(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pablo/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/agent_framework/_clients.py\", line 339, in get_response\n",
      "    return await self._inner_get_response(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pablo/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/agent_framework_azure_ai/_chat_client.py\", line 355, in _inner_get_response\n",
      "    return await ChatResponse.from_chat_response_generator(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pablo/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/agent_framework/_types.py\", line 2920, in from_chat_response_generator\n",
      "    async for update in updates:\n",
      "  File \"/Users/pablo/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/agent_framework_azure_ai/_chat_client.py\", line 374, in _inner_get_streaming_response\n",
      "    *(await self._create_agent_stream(agent_id, run_options, required_action_results))\n",
      "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pablo/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/agent_framework_azure_ai/_chat_client.py\", line 463, in _create_agent_stream\n",
      "    final_thread_id = await self._prepare_thread(thread_id, thread_run, run_options)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pablo/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/agent_framework_azure_ai/_chat_client.py\", line 495, in _prepare_thread\n",
      "    await self.agents_client.runs.cancel(thread_id, thread_run.id)\n",
      "  File \"/Users/pablo/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/azure/core/tracing/decorator_async.py\", line 119, in wrapper_use_tracer\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pablo/Desktop/githubRepos/teaching/northwestern/northwestern-fy26-msai-foundry-agentic-ai/.venv/lib/python3.11/site-packages/azure/ai/agents/aio/operations/_operations.py\", line 2155, in cancel\n",
      "    raise HttpResponseError(response=response, model=error)\n",
      "azure.core.exceptions.HttpResponseError: (None) Cannot cancel run with status 'incomplete'.\n",
      "Code: None\n",
      "Message: Cannot cancel run with status 'incomplete'.\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import nest_asyncio\n",
    "from agent_framework.azure import AzureAIAgentsProvider\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "\n",
    "# Enable nested event loops for Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Global state for the agent session\n",
    "class AgentSession:\n",
    "    def __init__(self):\n",
    "        self.agent = None\n",
    "        self.thread = None\n",
    "        self.provider = None\n",
    "        self.credential = None\n",
    "        self.initialized = False\n",
    "    \n",
    "    async def initialize(self):\n",
    "        if not self.initialized:\n",
    "            self.credential = DefaultAzureCredential()\n",
    "            self.provider = AzureAIAgentsProvider(credential=self.credential)\n",
    "            await self.provider.__aenter__()\n",
    "            \n",
    "            self.agent = await self.provider.create_agent(\n",
    "                name=\"GradResearchAssistant\",\n",
    "                instructions=\"\"\"You are a Graduate Research Assistant AI helping students succeed.\n",
    "\n",
    "Your capabilities (3 tools):\n",
    "üìä analyze_grades(course) ‚Äî Query grade database for a specific course\n",
    "üìÖ check_deadlines(course) ‚Äî Query deadline database (use 'all' for all courses)\n",
    "üìß send_email(to, subject, message) ‚Äî Send email notifications\n",
    "\n",
    "Available courses: CS 101, STAT 302, ML 450\n",
    "\n",
    "When helping students:\n",
    "1. Query databases to understand their situation\n",
    "2. If they want reminders or notifications, use the email tool\n",
    "3. Be proactive about identifying concerns and suggesting solutions\n",
    "4. Be encouraging but honest about areas needing improvement\"\"\",\n",
    "                tools=[analyze_grades, check_deadlines, send_email],\n",
    "            )\n",
    "            self.thread = self.agent.get_new_thread()\n",
    "            self.initialized = True\n",
    "            print(\"‚úÖ Agent initialized!\")\n",
    "    \n",
    "    async def chat(self, message: str) -> str:\n",
    "        \"\"\"Process chat message with the agent.\"\"\"\n",
    "        try:\n",
    "            await self.initialize()\n",
    "            response = await self.agent.run(message, thread=self.thread)\n",
    "            return str(response)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return f\"‚ùå Error: {str(e)}\"\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the session for a new conversation.\"\"\"\n",
    "        self.thread = self.agent.get_new_thread() if self.agent else None\n",
    "\n",
    "# Create session\n",
    "session = AgentSession()\n",
    "\n",
    "# Gradio response function using messages format (Gradio 5.x default)\n",
    "async def respond(message: str, history: list):\n",
    "    \"\"\"Async handler for Gradio chat.\"\"\"\n",
    "    if not message.strip():\n",
    "        return history, \"\"\n",
    "    \n",
    "    # Get response from agent\n",
    "    bot_message = await session.chat(message)\n",
    "    \n",
    "    # Gradio 5.x expects list of dicts with role/content keys\n",
    "    history.append({\"role\": \"user\", \"content\": message})\n",
    "    history.append({\"role\": \"assistant\", \"content\": bot_message})\n",
    "    return history, \"\"\n",
    "\n",
    "# Build Gradio interface\n",
    "with gr.Blocks(title=\"Graduate Research Assistant\") as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # üéì Graduate Research Assistant\n",
    "    \n",
    "    Chat with your AI assistant that has access to your academic data!\n",
    "    \n",
    "    **Available Tools:**\n",
    "    - üìä **Grades** ‚Äî \"How am I doing in CS 101?\"\n",
    "    - üìÖ **Deadlines** ‚Äî \"Check all my deadlines\"\n",
    "    - üìß **Email** ‚Äî \"Send me a summary at student@northwestern.edu\"\n",
    "    \n",
    "    **Courses:** CS 101, STAT 302, ML 450\n",
    "    \"\"\")\n",
    "    \n",
    "    chatbot = gr.Chatbot(\n",
    "        height=400,\n",
    "        placeholder=\"Ask about your grades, deadlines, or request email notifications...\",\n",
    "    )\n",
    "    \n",
    "    msg = gr.Textbox(\n",
    "        placeholder=\"Type your message here... (e.g., 'What are my grades in ML 450?')\",\n",
    "        label=\"Your Message\",\n",
    "        lines=2,\n",
    "    )\n",
    "    \n",
    "    with gr.Row():\n",
    "        submit = gr.Button(\"Send üì§\", variant=\"primary\")\n",
    "        clear = gr.Button(\"Clear üóëÔ∏è\")\n",
    "    \n",
    "    gr.Examples(\n",
    "        examples=[\n",
    "            \"What are my grades in CS 101?\",\n",
    "            \"Check all my upcoming deadlines\",\n",
    "            \"How am I doing in STAT 302? Any urgent deadlines?\",\n",
    "            \"Send a deadline reminder to student@northwestern.edu\",\n",
    "        ],\n",
    "        inputs=msg,\n",
    "    )\n",
    "    \n",
    "    # Event handlers\n",
    "    msg.submit(respond, [msg, chatbot], [chatbot, msg])\n",
    "    submit.click(respond, [msg, chatbot], [chatbot, msg])\n",
    "    clear.click(lambda: [], outputs=[chatbot])\n",
    "\n",
    "# Launch\n",
    "print(\"üöÄ Launching Gradio interface...\")\n",
    "demo.launch(share=False, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you learned how to build an AI agent with **4 tools from 3 different sources**:\n",
    "\n",
    "### Tool Architecture\n",
    "\n",
    "| Tool | Source | Lab | Purpose |\n",
    "|------|--------|-----|---------|\n",
    "| `analyze_grades` | Local Function | ‚Äî | Query grade database |\n",
    "| `check_deadlines` | Local Function | ‚Äî | Query deadline database |\n",
    "| `send_email` | Logic App | Lab 2 | Email notifications |\n",
    "| `analyze_data` | Azure Function | Lab 1 | Statistical computation |\n",
    "\n",
    "### Key Patterns Learned\n",
    "\n",
    "**1. Local Functions** ‚Äî Fast, in-process tools\n",
    "```python\n",
    "def my_tool(param: Annotated[str, Field(description=\"...\")]) -> str:\n",
    "    return DATABASE[param]\n",
    "```\n",
    "\n",
    "**2. Logic App Tools** ‚Äî Workflow automation\n",
    "```python\n",
    "async def send_email(to, subject, message) -> str:\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        await session.post(LOGIC_APP_URL, json={...})\n",
    "```\n",
    "\n",
    "**3. Azure Function Tools** ‚Äî Serverless compute\n",
    "```python\n",
    "async def analyze_data(values) -> str:\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        await session.post(FUNCTION_URL, json={\"values\": [...]})\n",
    "```\n",
    "\n",
    "### When to Use Each Tool Type\n",
    "\n",
    "| Tool Type | Best For |\n",
    "|-----------|----------|\n",
    "| **Local** | Database queries, formatting, fast operations |\n",
    "| **Logic App** | Emails, Slack, Teams, calendar, workflows |\n",
    "| **Azure Function** | Heavy computation, ML inference, data processing |\n",
    "\n",
    "\n",
    "**Congratulations!** You've built a Graduate Research Assistant that combines local functions, Logic Apps, and Azure Functions using Microsoft Agent Framework!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "northwestern-fy26-msai-foundry-agentic-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
